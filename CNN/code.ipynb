{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.CNN基础\n",
    "\n",
    "### 二维卷积层实现互相关运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "def corr2d(X,K):\n",
    "    H,W=X.shape\n",
    "    h,w=K.shape\n",
    "    Y=torch.zeros(H-h+1,W-w+1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[0]):\n",
    "            Y[i,j]=(X[i:i+h,j:j+w]*K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二维卷积层 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5, loss 3.257\n",
      "Step 10, loss 0.766\n",
      "Step 15, loss 0.195\n",
      "Step 20, loss 0.052\n",
      "Step 25, loss 0.014\n",
      "Step 30, loss 0.004\n",
      "tensor([[ 0.9832, -0.9852]])\n",
      "tensor([0.0007])\n"
     ]
    }
   ],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias\n",
    "    \n",
    "#例子6*8图像，中间4列为黑(0),其余为白(1)，\n",
    "#检测颜色边缘，标签是一个 6×7 的二维数组，第2列是1（从1到0的边缘），第6列是-1（从0到1的边缘）\n",
    "X = torch.ones(6, 8)\n",
    "Y = torch.zeros(6, 7)\n",
    "X[:, 2: 6] = 0\n",
    "Y[:, 1] = 1\n",
    "Y[:, 5] = -1\n",
    "conv2d = Conv2D(kernel_size=(1, 2))\n",
    "step = 30\n",
    "lr = 0.01\n",
    "for i in range(step):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = ((Y_hat - Y) ** 2).sum()\n",
    "    l.backward()\n",
    "    # 梯度下降\n",
    "    conv2d.weight.data -= lr * conv2d.weight.grad\n",
    "    conv2d.bias.data -= lr * conv2d.bias.grad\n",
    "    # 梯度清零\n",
    "    conv2d.weight.grad.zero_()\n",
    "    conv2d.bias.grad.zero_()\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print('Step %d, loss %.3f' % (i + 1, l.item()))       \n",
    "print(conv2d.weight.data)\n",
    "print(conv2d.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积运算\n",
    "\n",
    "卷积运算将卷积核上下翻转、 左右翻转后在做互相关运算，但由于卷积层核函数可学习，因此互相关运算可以和卷积运算起到相同作用\n",
    "\n",
    "### 特征图与感受野\n",
    "\n",
    "二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素x的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做的x感受野（receptive field）\n",
    "\n",
    "### 1* 1卷积核\n",
    "\n",
    "1* 1卷积核可以在不改变高和宽的情况下，调整通道数。\n",
    "\n",
    "### 卷积层优势\n",
    "\n",
    "(1)与全连接层相比，可以提取局部信息的能力  (2)参数量更少\n",
    "\n",
    "### 卷积层简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape:  torch.Size([4, 3, 3, 5])\n",
      "weight.shape:  torch.Size([3, 2, 3, 5])\n",
      "bias.shape:  torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "X=torch.rand(4,2,3,5)\n",
    "#in_channels表示图像通道数，out_channels 卷积后的通道数，stride步长，padding填充\n",
    "conv2d = nn.Conv2d(in_channels=2, out_channels=3, kernel_size=(3, 5), stride=1, padding=(1, 2))\n",
    "Y = conv2d(X)\n",
    "print('Y.shape: ', Y.shape)\n",
    "print('weight.shape: ', conv2d.weight.shape)\n",
    "print('bias.shape: ', conv2d.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.,  7.],\n",
      "          [ 8.,  9., 10., 11.],\n",
      "          [12., 13., 14., 15.]],\n",
      "\n",
      "         [[16., 17., 18., 19.],\n",
      "          [20., 21., 22., 23.],\n",
      "          [24., 25., 26., 27.],\n",
      "          [28., 29., 30., 31.]]]])\n",
      "tensor([[[[ 5.,  6.,  7.,  7.],\n",
      "          [13., 14., 15., 15.]],\n",
      "\n",
      "         [[21., 22., 23., 23.],\n",
      "          [29., 30., 31., 31.]]]])\n"
     ]
    }
   ],
   "source": [
    "#nn.MaxPool2d是最大池化，nn.AvgPool2d是平均池化\n",
    "#stride为池化窗口的大小\n",
    "X = torch.arange(32, dtype=torch.float32).view(1, 2, 4, 4)\n",
    "pool2d = nn.MaxPool2d(kernel_size=3, padding=1, stride=(2, 1))\n",
    "Y = pool2d(X)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.LeNet\n",
    "\n",
    "### 使用全连接层的局限性\n",
    "\n",
    "(1)图像铺平后同一列邻近像素在这个向量中相距较远，构成的模式难以被识别\n",
    "\n",
    "(2)大尺寸输入图像使用全连接层的尺寸过大\n",
    "\n",
    "### LeNet\n",
    "\n",
    "LeNet由卷积层块和全连接层两部分构成。\n",
    "\n",
    "卷积层块的基本单位是卷积层接平均池化层，用于识别图像的空间模式，如线条和物体局部，之后的平均池化用于降低卷积层对位置的敏感性。\n",
    "\n",
    "卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用 5×5 的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。\n",
    "\n",
    "全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。\n",
    "\n",
    "### 模型实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "#定义模型\n",
    "class Flatten(torch.nn.Module):  #展平操作\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "#将图像大小重定型\n",
    "class Reshape(torch.nn.Module): \n",
    "    def forward(self, x):\n",
    "        return x.view(-1,1,28,28)      #(B x C x H x W)\n",
    "net = torch.nn.Sequential(     #Lelet                                                  \n",
    "    Reshape(),\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2), #b*1*28*28  =>b*6*28*28\n",
    "    nn.Sigmoid(),                                                       \n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),                              #b*6*28*28  =>b*6*14*14\n",
    "    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),           #b*6*14*14  =>b*16*10*10\n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),                              #b*16*10*10  => b*16*5*5\n",
    "    Flatten(),                                                          #b*16*5*5   => b*400\n",
    "    nn.Linear(in_features=16*5*5, out_features=120),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "X_train, y_train = load_mnist('C:/Users/wangk/Desktop/DIVE_INTO_DEEP_LEARNING', kind='train')\n",
    "X_test, y_test = load_mnist('C:/Users/wangk/Desktop/DIVE_INTO_DEEP_LEARNING', kind='t10k')\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "#转换数据\n",
    "X_train = torch.tensor(X_train.reshape(60000,28,28), dtype=torch.float)\n",
    "X_test = torch.tensor(X_test.reshape(10000,28,28), dtype=torch.float)\n",
    "y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "dataset_train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(dataset_train, batch_size, shuffle=True)\n",
    "dataset_test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "test_iter = torch.utils.data.DataLoader(dataset_test, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算准确率\n",
    "'''\n",
    "(1). net.train()\n",
    "  启用 BatchNormalization 和 Dropout，将BatchNormalization和Dropout置为True\n",
    "(2). net.eval()\n",
    "不启用 BatchNormalization 和 Dropout，将BatchNormalization和Dropout置为False\n",
    "'''\n",
    "\n",
    "def evaluate_accuracy(data_iter, net,device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    acc_sum,n = torch.tensor([0],dtype=torch.float32,device=device),0\n",
    "    for X,y in data_iter:\n",
    "        # If device is the GPU, copy the data to the GPU.\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))  #[[0.2 ,0.4 ,0.5 ,0.6 ,0.8] ,[ 0.1,0.2 ,0.4 ,0.3 ,0.1]] => [ 4 , 2 ]\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use GPU\n",
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "device = try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练函数\n",
    "def train_ch5(net, train_iter, test_iter,criterion, num_epochs, batch_size, device,lr=None):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n",
    "        train_acc_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n",
    "        n, start = 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            net.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            X,y = X.to(device),y.to(device) \n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y = y.long()\n",
    "                train_l_sum += loss.float()\n",
    "                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
    "                n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net,device)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cpu\n",
      "epoch 1, loss 0.0064, train acc 0.356, test acc 0.520, time 32.7 sec\n",
      "epoch 2, loss 0.0032, train acc 0.681, test acc 0.567, time 34.4 sec\n",
      "epoch 3, loss 0.0025, train acc 0.744, test acc 0.748, time 34.7 sec\n",
      "epoch 4, loss 0.0022, train acc 0.775, test acc 0.769, time 34.3 sec\n",
      "epoch 5, loss 0.0020, train acc 0.800, test acc 0.802, time 36.3 sec\n",
      "epoch 6, loss 0.0019, train acc 0.812, test acc 0.813, time 34.5 sec\n",
      "epoch 7, loss 0.0018, train acc 0.823, test acc 0.776, time 35.8 sec\n",
      "epoch 8, loss 0.0017, train acc 0.835, test acc 0.805, time 34.3 sec\n",
      "epoch 9, loss 0.0016, train acc 0.841, test acc 0.808, time 35.1 sec\n",
      "epoch 10, loss 0.0016, train acc 0.849, test acc 0.805, time 34.4 sec\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "lr, num_epochs = 0.9, 10\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net.apply(init_weights)\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   #交叉熵描述了两个概率分布之间的距离，交叉熵越小说明两者之间越接近\n",
    "train_ch5(net, train_iter, test_iter, criterion,num_epochs, batch_size,device, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 28, 28]) torch.Size([256])\n",
      "tensor([9, 7, 1, 9, 4, 0, 8, 6, 7, 6])\n",
      "tensor([9, 7, 1, 9, 2, 6, 8, 2, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "for testdata,testlabe in test_iter:\n",
    "    testdata,testlabe = testdata.to(device),testlabe.to(device)\n",
    "    break\n",
    "print(testdata.shape,testlabe.shape)\n",
    "net.eval()\n",
    "y_pre = net(testdata)\n",
    "print(torch.argmax(y_pre,dim=1)[:10])\n",
    "print(testlabe[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.CNN进阶\n",
    "\n",
    "### LeNet的缺点\n",
    "\n",
    "在大的真实数据集上表现不如意:(1)神经网络计算复杂 (2)没有大量深入研究参数初始化和非凸优化领域\n",
    "\n",
    "### AlexNet\n",
    "\n",
    "(1)8层变换，包括5层卷积和2个全连接隐层，以及1个全连接输出层\n",
    "(2)激活函数使用relu，使用dropout (3)使用数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#定义AlexNet\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            #由于使用CPU镜像，精简网络，若为GPU镜像可添加该层\n",
    "            #nn.Linear(4096, 4096),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output\n",
    "net = AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG\n",
    "\n",
    "重复使用简单的基础块构建模型。基础块包括数个相同的填充为1，3* 3的卷积层，接一个步幅为2，2 * 2的最大池化层。卷积层保持输入的高和宽不变，池化层对其减半"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.shape[0],-1)\n",
    "def vgg_block(num_convs, in_channels, out_channels): #卷积层个数，输入通道数，输出通道数\n",
    "    blk = []\n",
    "    for i in range(num_convs):\n",
    "        if i == 0:\n",
    "            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        else:\n",
    "            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        blk.append(nn.ReLU())\n",
    "    blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # 这里会使宽高减半\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512))\n",
    "# 经过5个vgg_block, 宽高会减半5次, 变成 224/32 = 7\n",
    "fc_features = 512 * 7 * 7 # c * w * h\n",
    "fc_hidden_units = 4096 # 任意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch, fc_features, fc_hidden_units=4096):\n",
    "    net = nn.Sequential()\n",
    "    # 卷积层部分\n",
    "    for i, (num_convs, in_channels, out_channels) in enumerate(conv_arch):\n",
    "        # 每经过一个vgg_block都会使宽高减半\n",
    "        net.add_module(\"vgg_block_\" + str(i+1), vgg_block(num_convs, in_channels, out_channels))\n",
    "    # 全连接层部分\n",
    "    net.add_module(\"fc\", nn.Sequential(FlattenLayer(),\n",
    "                                 nn.Linear(fc_features, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, 10)\n",
    "                                ))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg_block_1 output shape:  torch.Size([1, 64, 112, 112])\n",
      "vgg_block_2 output shape:  torch.Size([1, 128, 56, 56])\n",
      "vgg_block_3 output shape:  torch.Size([1, 256, 28, 28])\n",
      "vgg_block_4 output shape:  torch.Size([1, 512, 14, 14])\n",
      "vgg_block_5 output shape:  torch.Size([1, 512, 7, 7])\n",
      "fc output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "net = vgg(conv_arch, fc_features, fc_hidden_units)\n",
    "X = torch.rand(1, 1, 224, 224)\n",
    "\n",
    "# named_children获取一级子模块及其名字(named_modules会返回所有子模块,包括子模块的子模块)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (vgg_block_1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_3): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_4): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_5): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): FlattenLayer()\n",
      "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ratio = 8\n",
    "small_conv_arch = [(1, 1, 64//ratio), (1, 64//ratio, 128//ratio), (2, 128//ratio, 256//ratio), \n",
    "                   (2, 256//ratio, 512//ratio), (2, 512//ratio, 512//ratio)]\n",
    "net = vgg(small_conv_arch, fc_features // ratio, fc_hidden_units // ratio)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NiN网络\n",
    "\n",
    "LeNet,AlexNet和VGG均先使用卷积层构成的模块抽取空间特征，再使用全连接层欧城的模块输出分类结果。\n",
    "\n",
    "NiN：串联多个由卷积层和全连接层构成的小网络构建深层网络，⽤了输出通道数等于标签类别数的NiN块，然后使⽤全局平均池化层对每个通道中所有元素求平均并直接⽤于分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(in_channels, out_channels, kernel_size, stride, padding):\n",
    "    blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU())\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAvgPool2d(nn.Module):\n",
    "    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, stride=4, padding=0),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, stride=1, padding=1),\n",
    "    GlobalAvgPool2d(), \n",
    "    # 将四维的输出转成二维的输出，其形状为(批量大小, 10)\n",
    "    FlattenLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 output shape:  torch.Size([1, 96, 54, 54])\n",
      "1 output shape:  torch.Size([1, 96, 26, 26])\n",
      "2 output shape:  torch.Size([1, 256, 26, 26])\n",
      "3 output shape:  torch.Size([1, 256, 12, 12])\n",
      "4 output shape:  torch.Size([1, 384, 12, 12])\n",
      "5 output shape:  torch.Size([1, 384, 5, 5])\n",
      "6 output shape:  torch.Size([1, 384, 5, 5])\n",
      "7 output shape:  torch.Size([1, 10, 5, 5])\n",
      "8 output shape:  torch.Size([1, 10, 1, 1])\n",
      "9 output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 1, 224, 224)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleLeNet\n",
    "\n",
    "由Inception模块组成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1 - c4为每条线路里的层的输出通道数\n",
    "    def __init__(self, in_c, c1, c2, c3, c4):\n",
    "        super(Inception, self).__init__()\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1 x 1卷积层后接5 x 5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)  # 在通道维上连结输出"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
